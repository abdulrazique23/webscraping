import requests
from bs4 import BeautifulSoup
import pandas as pd

# Function to scrape data from an e-commerce website
def scrape_website(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    # Send a request to the website
    response = requests.get(url, headers=headers)
    
    # Parse the HTML content
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Lists to store extracted data
    product_names = []
    product_prices = []
    product_ratings = []
    
    # Find all product containers (change these according to website structure)
    products = soup.find_all('div', class_='product-container')
    
    # Loop through each product and extract the relevant data
    for product in products:
        # Extract product name
        name = product.find('h2', class_='product-name').text.strip()
        product_names.append(name)
        
        # Extract product price
        price = product.find('span', class_='price').text.strip()
        product_prices.append(price)
        
        # Extract product rating (if available)
        rating = product.find('span', class_='rating').text.strip() if product.find('span', class_='rating') else 'No Rating'
        product_ratings.append(rating)
    
    # Create a DataFrame to store the scraped data
    product_data = pd.DataFrame({
        'Product Name': product_names,
        'Price': product_prices,
        'Rating': product_ratings
    })
    
    # Save the data to a CSV file
    product_data.to_csv('scraped_products.csv', index=False)
    print("Data saved to 'scraped_products.csv'")

# Example usage
url = 'https://example-ecommerce-site.com/products'  # Replace with your target e-commerce website
scrape_website(url)
